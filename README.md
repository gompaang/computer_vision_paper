# computer_vision_paper

## paper_list
- computer vision (CNN)
  - image classification
  - object detection
  - segmentation
- vision transformer
- self-supervised learning
- medical AI



## Computer Vision (CNN)

### image classification
|Name|year|paper|summary|code|
|---|---|---|---|---|
|AlexNet (ImageNet Classification with Deep Convolutional Neural Networks)|NeurPS 2012|[paper](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)|[summary](https://mirror-dragonfly-2a2.notion.site/AlexNet-2012-14b1e41747b340f380d058e0604ea657)|[code](https://github.com/gompaang/cifar10-classification/blob/master/models/alexnet.py)|
|VGGNet (Very Deep Convolutional Networks For Large-Scale Image Recognition)|ICLR 2015|[paper](https://arxiv.org/pdf/1409.1556.pdf)|[summary](https://mirror-dragonfly-2a2.notion.site/VGGNet-2015-3c8abd1c60b646a4a173d57f2f3c4f57)|[code](https://github.com/gompaang/cifar10-classification/blob/master/models/vggnet.py)|
|ResNet (Deep Residual Learning for Image Recognition)|CVPR 2015|[paper](https://arxiv.org/pdf/1512.03385.pdf)|[summary](https://mirror-dragonfly-2a2.notion.site/ResNet-2015-ab49bb53ac194b6aac7e56fce4499f98)|[code](https://github.com/gompaang/cifar10-classification/blob/master/models/resnet.py)|
|SENet (Squeeze-and-Excitation Networks)|CVPR 2018|[paper](https://arxiv.org/pdf/1709.01507.pdf)|[summary](https://mirror-dragonfly-2a2.notion.site/SENet-2018-481b18a669fe4be88e8a2034e37c1999)||

### object detection
|Name|year|paper|summary|code|
|---|---|---|---|---|
|R-CNN (Rich feature hierarchies for accurate object detection and semantiv segmentation)|ILSVRC 2013|[paper](https://arxiv.org/abs/1311.2524)|[summary](https://mirror-dragonfly-2a2.notion.site/R-CNN-2014-967531ae120f41febd53fe331c9dbc61)||
|Fast R-CNN|2015|[paper](https://arxiv.org/pdf/1504.08083.pdf)|[summary](https://mirror-dragonfly-2a2.notion.site/Fast-R-CNN-2015-6aaf793a79c645c1a82cbdd18ed61e36)||
|Faster R-CNN (Towards Real-Time Object Detection with Region Proposal Networks)|NIPS 2015|[paper](https://arxiv.org/pdf/1506.01497.pdf)|[summary](https://mirror-dragonfly-2a2.notion.site/Faster-R-CNN-2016-59bca3f94a5d4b13a64cc29f50829d3f)||
|YOLO (You Only Look Once: Unified, Real-Time Object Detection)|2016|[paper](https://arxiv.org/pdf/1506.02640.pdf)|[summary](https://mirror-dragonfly-2a2.notion.site/YOLO-2016-bbf62be633864d9496302cc39fed227a)||
|SSD (Single Shot MultiBox Detector)|2016|[paper](https://arxiv.org/pdf/1512.02325.pdf)|[summary](https://mirror-dragonfly-2a2.notion.site/SSD-2016-83db924b7b104af5adf125595c816747)||

### segmentation
|Name|year|paper|summary|code|
|---|---|---|---|---|
|U-Net (Convolutional Networks for Biomedical Image Segmentation)|MICCAI 2015|[paper](https://arxiv.org/pdf/1505.04597.pdf)||



## Vision Transformer (ViT)
|Name|year|paper|summary|code|
|---|---|---|---|---|
|ViT (An Image Is Worth 16x16 Words: Transformers For Image Recognition At Scale)|ICLR 2021|[paper](https://arxiv.org/pdf/2010.11929.pdf)||
|Swin Transformer (Hierarchical Vision Transformer using Shifted Windows)|ICCV 2021|[paper](https://arxiv.org/pdf/2103.14030.pdf)||
|MLP-Mixer (An all-MLP Architecture for Vision)|2021|[paper](https://arxiv.org/pdf/2105.01601.pdf)|||



## Self-supervised learning
|Name|year|paper|summary|code|
|---|---|---|---|---|
|SimCLR (A Single Framework for Contrastive Learning of Visual Representations)|ICML 2020|[paper](https://arxiv.org/pdf/2002.05709.pdf)|[summary](https://mirror-dragonfly-2a2.notion.site/SimCLR-923b3c90e90c4a57b7c5018bb40a249b)||
|MoCo (Momentum Contrast for Unsupervised Visual Representation Learning)|CVPR 2020|[paper](https://arxiv.org/pdf/1911.05722.pdf)|[summary](https://mirror-dragonfly-2a2.notion.site/MoCo-d85d8542b356448baa60b4aa5e3c0293)||
|BYOL (Bootstrap Your Own Latent A New Approach to Self-Supervised Learning)|NeurIPS 2020|[paper](https://arxiv.org/pdf/2006.07733.pdf)|[summary](https://hey-stranger.tistory.com/236)||
|DINO (Emerging Properties in Self-supervised Vision Transformers)|2021|[paper](https://arxiv.org/pdf/2104.14294v2.pdf)|[summary](https://hey-stranger.tistory.com/237)||
|SimCLR v2 (Big Self-Supervised Models are Strong Semi-Supervised Learners)|NeurIPS 2020|[paper](https://arxiv.org/pdf/2006.10029.pdf)|||
|MoCo v2 (Improved Baselines with Momentum Contrastive Learning)|2020|[paper](https://arxiv.org/pdf/2003.04297.pdf)|||
|MoCo v3 (An Empirical Study of Training Self-Supervised Vision Transformers)|ICCV 2021|[paper](https://arxiv.org/pdf/2104.02057.pdf)|||



## Medical AI
|Name|year|paper|summary|code|
|---|---|---|---|---|
|MICLe (Big Self-Supervised Models Advance Medical Image Classifications)|ICCV 2021|[paper](https://arxiv.org/pdf/2101.05224.pdf)|[summary](https://mirror-dragonfly-2a2.notion.site/Big-self-supervised-Models-Advance-Medical-Image-Classification-4e606a2df3ad42a2a1b2bc0379497d9a)||
|TransUNet (Transformers Make Strong Encoders for Medical Image Segmentation)|2021|[paper](https://arxiv.org/pdf/2102.04306.pdf)|||
|Unetr (UNETR: Transformers for 3D Medical Image Segmentation)|2021|[paper](https://arxiv.org/pdf/2103.10504v3.pdf)|||
|TransBTS (Multimodal Brain Tumor Segmentation Using Transformer)|2021|[paper](https://arxiv.org/pdf/2103.04430v2.pdf)|||


